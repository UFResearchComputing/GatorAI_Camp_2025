{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UFResearchComputing/gatorAI_summer_camp_2024/blob/main/01_full_of_emotion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><img src=\"images/gator_ai_camp_2024_logo_200.png\" align=\"right\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KhpJb5VI79P"
      },
      "source": [
        "# Gator AI Summer Camp 2025\n",
        "\n",
        "In this notebook, we're going to use Python to create a deep learning model that can take images of faces and output the emotion being expressed.\n",
        "\n",
        "The dataset we're going to use is the FER-2013 dataset, which contains 35,887 grayscale images of faces. Each image is 48x48 pixels and is labeled with one of seven emotions: anger, disgust, fear, happiness, sadness, surprise, or neutral. The dataset and more information can be found [on Kaggle](https://www.kaggle.com/datasets/msambare/fer2013/data).\n",
        "\n",
        "**Note:** One issue with the dataset is that it has relatively few images in the disgust category, so we drop that category for this exercise.\n",
        "\n",
        "To build our model, we'll use the Keras deep learning library, which provides a high-level interface for building and training neural networks. We'll start by loading the dataset and exploring the images, then we'll build and train a convolutional neural network (CNN) to classify the emotions in the images.\n",
        "\n",
        "**Before you get started, make sure to select a Runtime with a GPU!** <img src='images/colab_change_runtime_type.png' align='right' width='50%' alt='Image of the Runtime menu options in Google Colab'>\n",
        "* Go to the **\"Runtime\"** menu\n",
        "* Select **\"Change runtime type\"**\n",
        "* Select **\"T4 GPU\"** and click **\"Save\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AVz8_6AYI79Q",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from functools import reduce\n",
        "import itertools\n",
        "from collections import Counter\n",
        "import kagglehub\n",
        "\n",
        "\n",
        "# Import the libraries for CNNs\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "# Import the libraries for the evaluation\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading dataset from Kaggle...\n",
            "Dataset downloaded to: C:\\Users\\i.lutticken\\.cache\\kagglehub\\datasets\\msambare\\fer2013\\versions\\1\n",
            "Contents of C:\\Users\\i.lutticken\\.cache\\kagglehub\\datasets\\msambare\\fer2013\\versions\\1:\n",
            "  Directory: test\n",
            "  Directory: train\n",
            "Found train and test directories, copying to data/\n",
            "Directories copied successfully\n",
            "\n",
            "Contents of data directory:\n",
            "  Directory: test\n",
            "    Emotion categories: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
            "  Directory: train\n",
            "    Emotion categories: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
            "Removed data/train/disgust folder\n",
            "Removed data/test/disgust folder\n",
            "Dataset preparation complete!\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset using kagglehub\n",
        "print(\"Downloading dataset from Kaggle...\")\n",
        "dataset_path = kagglehub.dataset_download(\"msambare/fer2013\")\n",
        "print(f\"Dataset downloaded to: {dataset_path}\")\n",
        "\n",
        "# Create data directory if it doesn't exist\n",
        "if not os.path.exists(\"data\"):\n",
        "    os.makedirs(\"data\")\n",
        "    print(\"Created 'data' directory\")\n",
        "\n",
        "# Check what files/folders are in the downloaded dataset\n",
        "print(f\"Contents of {dataset_path}:\")\n",
        "for item in os.listdir(dataset_path):\n",
        "    item_path = os.path.join(dataset_path, item)\n",
        "    if os.path.isdir(item_path):\n",
        "        print(f\"  Directory: {item}\")\n",
        "    else:\n",
        "        print(f\"  File: {item}\")\n",
        "\n",
        "# Look for zip file first\n",
        "zip_file = None\n",
        "for file in os.listdir(dataset_path):\n",
        "    if file.endswith(\".zip\"):\n",
        "        zip_file = os.path.join(dataset_path, file)\n",
        "        break\n",
        "\n",
        "if zip_file:\n",
        "    # Extract the zip file to the data directory\n",
        "    print(f\"Extracting {zip_file} to data/\")\n",
        "    with zipfile.ZipFile(zip_file, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\"data/\")\n",
        "    print(\"Extraction complete\")\n",
        "else:\n",
        "    # No zip file found, check if train/test directories already exist\n",
        "    train_dir = os.path.join(dataset_path, \"train\")\n",
        "    test_dir = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "    if os.path.exists(train_dir) and os.path.exists(test_dir):\n",
        "        print(\"Found train and test directories, copying to data/\")\n",
        "        # Copy the train and test directories\n",
        "        shutil.copytree(train_dir, os.path.join(\"data\", \"train\"), dirs_exist_ok=True)\n",
        "        shutil.copytree(test_dir, os.path.join(\"data\", \"test\"), dirs_exist_ok=True)\n",
        "        print(\"Directories copied successfully\")\n",
        "    else:\n",
        "        # Look for any other structure\n",
        "        print(\"Searching for dataset files in subdirectories...\")\n",
        "        for root, dirs, files in os.walk(dataset_path):\n",
        "            if \"train\" in dirs and \"test\" in dirs:\n",
        "                train_source = os.path.join(root, \"train\")\n",
        "                test_source = os.path.join(root, \"test\")\n",
        "                print(f\"Found train/test directories in: {root}\")\n",
        "                shutil.copytree(\n",
        "                    train_source, os.path.join(\"data\", \"train\"), dirs_exist_ok=True\n",
        "                )\n",
        "                shutil.copytree(\n",
        "                    test_source, os.path.join(\"data\", \"test\"), dirs_exist_ok=True\n",
        "                )\n",
        "                print(\"Directories copied successfully\")\n",
        "                break\n",
        "        else:\n",
        "            print(\"Could not find train/test directories in the downloaded dataset\")\n",
        "\n",
        "# Verify the data directory structure\n",
        "if os.path.exists(\"data\"):\n",
        "    print(f\"\\nContents of data directory:\")\n",
        "    for item in os.listdir(\"data\"):\n",
        "        item_path = os.path.join(\"data\", item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"  Directory: {item}\")\n",
        "            # Show subdirectories (emotion categories)\n",
        "            if os.path.exists(item_path):\n",
        "                subdirs = [\n",
        "                    d\n",
        "                    for d in os.listdir(item_path)\n",
        "                    if os.path.isdir(os.path.join(item_path, d))\n",
        "                ]\n",
        "                print(f\"    Emotion categories: {subdirs}\")\n",
        "\n",
        "# Delete the disgust folders as there are so few examples in that category\n",
        "disgust_train_path = os.path.join(\"data\", \"train\", \"disgust\")\n",
        "disgust_test_path = os.path.join(\"data\", \"test\", \"disgust\")\n",
        "\n",
        "if os.path.exists(disgust_train_path):\n",
        "    shutil.rmtree(disgust_train_path)\n",
        "    print(\"Removed data/train/disgust folder\")\n",
        "\n",
        "if os.path.exists(disgust_test_path):\n",
        "    shutil.rmtree(disgust_test_path)\n",
        "    print(\"Removed data/test/disgust folder\")\n",
        "\n",
        "print(\"Dataset preparation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3Ioyd0sAI79R",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***********************************************************************\n",
            "Load data:\n",
            "  - Loading the dataset from: data/.\n",
            "  - Using a batch size of: 32.\n",
            "  - Resizing input images to: (80, 80, 1).\n",
            "  - Data augmentation: True.\n",
            "  - Balance classes: True.\n",
            "***********************************************************************\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'tensorflow.keras.layers' has no attribute 'experimental'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 179\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X_train, X_val\n\u001b[0;32m    177\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 179\u001b[0m X_train, X_val \u001b[38;5;241m=\u001b[39m load_display_data(\n\u001b[0;32m    180\u001b[0m     data_path,\n\u001b[0;32m    181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[0;32m    182\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    183\u001b[0m     show_pictures\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    184\u001b[0m     show_histogram\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    185\u001b[0m     augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    186\u001b[0m     balance_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    187\u001b[0m )\n",
            "Cell \u001b[1;32mIn[4], line 36\u001b[0m, in \u001b[0;36mload_display_data\u001b[1;34m(path, batch_size, shape, show_pictures, show_histogram, augment, balance_classes)\u001b[0m\n\u001b[0;32m     30\u001b[0m image_size \u001b[38;5;241m=\u001b[39m shape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Create the data augmentation pipeline if augmentation is enabled\u001b[39;00m\n\u001b[0;32m     33\u001b[0m data_augmentation \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     34\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m     35\u001b[0m         [\n\u001b[1;32m---> 36\u001b[0m             tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mRandomFlip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorizontal\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     37\u001b[0m             tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mRandomRotation(\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m     38\u001b[0m             tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mRandomZoom(\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m     39\u001b[0m             tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mRandomContrast(\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m     40\u001b[0m         ]\n\u001b[0;32m     41\u001b[0m     )\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m augment\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[0;32m     47\u001b[0m X_train \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m     48\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     49\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m     color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     54\u001b[0m )\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.keras.layers' has no attribute 'experimental'"
          ]
        }
      ],
      "source": [
        "def load_display_data(\n",
        "    path,\n",
        "    batch_size=32,\n",
        "    shape=(80, 80, 1),\n",
        "    show_pictures=True,\n",
        "    show_histogram=True,\n",
        "    augment=False,\n",
        "    balance_classes=False,\n",
        "):\n",
        "    \"\"\"Takes a path, batch size, target shape for images and optionally whether to show sample images, augment data, and balance classes.\n",
        "\n",
        "\n",
        "    Returns training and testing datasets\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    print(\"***********************************************************************\")\n",
        "\n",
        "\n",
        "    print(\"Load data:\")\n",
        "\n",
        "\n",
        "    print(f\"  - Loading the dataset from: {path}.\")\n",
        "\n",
        "\n",
        "    print(f\"  - Using a batch size of: {batch_size}.\")\n",
        "\n",
        "\n",
        "    print(f\"  - Resizing input images to: {shape}.\")\n",
        "\n",
        "\n",
        "    print(f\"  - Data augmentation: {augment}.\")\n",
        "\n",
        "\n",
        "    print(f\"  - Balance classes: {balance_classes}.\")\n",
        "\n",
        "\n",
        "    print(\"***********************************************************************\")\n",
        "\n",
        "\n",
        "    # Define the directory path\n",
        "\n",
        "\n",
        "    directory_path = path\n",
        "\n",
        "\n",
        "    # Define the batch size\n",
        "\n",
        "\n",
        "    batch_size = batch_size\n",
        "\n",
        "\n",
        "    # Define the image size using the 1st 2 elements of the shape parameter\n",
        "\n",
        "\n",
        "    # We don't need the number of channels here, just the dimensions to use\n",
        "\n",
        "\n",
        "    image_size = shape[:2]\n",
        "\n",
        "\n",
        "    # Create the data augmentation pipeline if augmentation is enabled\n",
        "\n",
        "\n",
        "    data_augmentation = (\n",
        "        tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "                tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "                tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "                tf.keras.layers.experimental.preprocessing.RandomContrast(0.1),\n",
        "            ]\n",
        "        )\n",
        "        if augment\n",
        "        else None\n",
        "    )\n",
        "\n",
        "\n",
        "    # Load the dataset\n",
        "\n",
        "\n",
        "    X_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        os.path.join(directory_path, \"train\"),\n",
        "        batch_size=batch_size,\n",
        "        image_size=image_size,\n",
        "        labels=\"inferred\",\n",
        "        label_mode=\"int\",\n",
        "        color_mode=\"grayscale\",\n",
        "    )\n",
        "\n",
        "\n",
        "    X_val = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        os.path.join(directory_path, \"test\"),\n",
        "        batch_size=batch_size,\n",
        "        image_size=image_size,\n",
        "        labels=\"inferred\",\n",
        "        label_mode=\"int\",\n",
        "        color_mode=\"grayscale\",\n",
        "    )\n",
        "\n",
        "\n",
        "    # Store class names before transforming the dataset\n",
        "\n",
        "\n",
        "    class_names = X_train.class_names\n",
        "\n",
        "\n",
        "    # Apply data augmentation to the training dataset if enabled\n",
        "\n",
        "\n",
        "    if augment:\n",
        "\n",
        "\n",
        "        X_train = X_train.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "\n",
        "\n",
        "    if show_pictures:\n",
        "        print(class_names)\n",
        "\n",
        "\n",
        "        # Display up to 3 images from each of the categories\n",
        "\n",
        "\n",
        "        class_images_dict = {class_name: [] for class_name in class_names}\n",
        "\n",
        "\n",
        "        # Collect images for each class\n",
        "\n",
        "\n",
        "        for images, labels in X_train:\n",
        "\n",
        "\n",
        "            images = images.numpy()\n",
        "\n",
        "\n",
        "            labels = labels.numpy()\n",
        "\n",
        "\n",
        "            for i, class_name in enumerate(class_names):\n",
        "\n",
        "\n",
        "                if len(class_images_dict[class_name]) < 3:\n",
        "\n",
        "\n",
        "                    # Filter images of the current class\n",
        "\n",
        "\n",
        "                    class_images = images[labels == i]\n",
        "\n",
        "\n",
        "                    class_images_dict[class_name].extend(\n",
        "                        class_images[: 3 - len(class_images_dict[class_name])]\n",
        "                    )\n",
        "\n",
        "\n",
        "            # Break if we have collected enough images for all classes\n",
        "\n",
        "\n",
        "            if all(len(imgs) >= 3 for imgs in class_images_dict.values()):\n",
        "\n",
        "\n",
        "                break\n",
        "\n",
        "\n",
        "        # Display the collected images\n",
        "\n",
        "\n",
        "        for class_name, class_images in class_images_dict.items():\n",
        "\n",
        "\n",
        "            fig, axs = plt.subplots(1, 3, figsize=(10, 10))\n",
        "\n",
        "\n",
        "            fig.subplots_adjust(\n",
        "                wspace=0, hspace=30\n",
        "            )  # Adjust the space between subplots\n",
        "\n",
        "\n",
        "            for j in range(len(class_images)):\n",
        "\n",
        "\n",
        "                ax = axs[j]\n",
        "\n",
        "\n",
        "                ax.imshow(class_images[j].astype(\"uint8\"), cmap=\"gray\")\n",
        "\n",
        "\n",
        "                ax.set_title(class_name)\n",
        "\n",
        "\n",
        "                ax.axis(\"off\")\n",
        "\n",
        "\n",
        "                ax.set_xticklabels([])\n",
        "\n",
        "\n",
        "                ax.set_yticklabels([])\n",
        "\n",
        "\n",
        "                ax.set_aspect(\"equal\")\n",
        "\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "    train_labels = []\n",
        "\n",
        "\n",
        "    if show_histogram:\n",
        "\n",
        "\n",
        "        # Collect all labels for training and validation datasets\n",
        "\n",
        "\n",
        "        for images, labels in X_train:\n",
        "\n",
        "\n",
        "            train_labels.extend(labels.numpy())\n",
        "\n",
        "\n",
        "        val_labels = []\n",
        "\n",
        "\n",
        "        for images, labels in X_val:\n",
        "\n",
        "\n",
        "            val_labels.extend(labels.numpy())\n",
        "\n",
        "\n",
        "        # Display the class distribution for the entire dataset\n",
        "\n",
        "\n",
        "        plt.figure(figsize=(15, 5))\n",
        "\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "\n",
        "\n",
        "        plt.title(\"Dataset\")\n",
        "\n",
        "\n",
        "        # Title for the total dataset\n",
        "\n",
        "\n",
        "        plt.hist(\n",
        "            train_labels + val_labels,\n",
        "            bins=np.arange(len(class_names) + 1) - 0.5,\n",
        "            edgecolor=\"black\",\n",
        "        )\n",
        "\n",
        "\n",
        "        plt.xticks(range(len(class_names)), labels=class_names, rotation=45)\n",
        "\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "\n",
        "\n",
        "        plt.title(\"Training\")\n",
        "\n",
        "\n",
        "        plt.hist(\n",
        "            train_labels, bins=np.arange(len(class_names) + 1) - 0.5, edgecolor=\"black\"\n",
        "        )\n",
        "\n",
        "\n",
        "        plt.xticks(range(len(class_names)), labels=class_names, rotation=45)\n",
        "\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "\n",
        "\n",
        "        plt.title(\"Validation\")\n",
        "\n",
        "\n",
        "        plt.hist(\n",
        "            val_labels, bins=np.arange(len(class_names) + 1) - 0.5, edgecolor=\"black\"\n",
        "        )\n",
        "\n",
        "\n",
        "        plt.xticks(range(len(class_names)), labels=class_names, rotation=45)\n",
        "\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    if balance_classes:\n",
        "\n",
        "\n",
        "        class_weights = class_weight.compute_class_weight(\n",
        "            class_weight=\"balanced\", classes=np.unique(train_labels), y=train_labels\n",
        "        )\n",
        "\n",
        "\n",
        "        class_weights = tf.constant(\n",
        "            list(class_weights)\n",
        "        )  # Convert to TensorFlow constant\n",
        "\n",
        "\n",
        "        # Apply class weights to the training dataset using tf.gather\n",
        "\n",
        "\n",
        "        X_train = X_train.map(\n",
        "            lambda img, label: (\n",
        "                img,\n",
        "                label,\n",
        "                tf.gather(class_weights, tf.cast(label, tf.int32)),\n",
        "            )\n",
        "        )\n",
        "\n",
        "\n",
        "        # (If needed, you could also adjust the validation set weights, but typically not necessary)\n",
        "\n",
        "\n",
        "        # X_val = X_val.map(lambda img, label: (img, label, tf.gather(class_weights, tf.cast(label, tf.int32))))\n",
        "\n",
        "\n",
        "    return X_train, X_val\n",
        "\n",
        "\n",
        "\n",
        "data_path = \"data/\"\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_val = load_display_data(\n",
        "    data_path,\n",
        "    batch_size=32,\n",
        "    shape=(80, 80, 1),\n",
        "    show_pictures=True,\n",
        "    show_histogram=True,\n",
        "    augment=True,\n",
        "    balance_classes=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnhLgZuKI79S",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the CNN model architecture\n",
        "\n",
        "\n",
        "def create_model(\n",
        "    input_shape, num_classes, padding=\"same\", activation=\"relu\", dropout_rate=0.2\n",
        "):\n",
        "    \"\"\"Takes the input shape and number of classes and returns a CNN model\"\"\"\n",
        "    print(\"***********************************************************************\")\n",
        "    print(\"Create model:\")\n",
        "    print(f\"  - Input shape: {input_shape}.\")\n",
        "    print(f\"  - Number of classes: {num_classes}.\")\n",
        "    print(\"***********************************************************************\")\n",
        "    # Create the model\n",
        "    model = Sequential(\n",
        "        [\n",
        "            Conv2D(\n",
        "                16, 3, padding=padding, activation=activation, input_shape=input_shape\n",
        "            ),\n",
        "            MaxPooling2D(),\n",
        "            Dropout(dropout_rate),\n",
        "            Conv2D(32, 3, padding=padding, activation=activation),\n",
        "            MaxPooling2D(),\n",
        "            Dropout(dropout_rate),\n",
        "            Conv2D(64, 3, padding=padding, activation=activation),\n",
        "            MaxPooling2D(),\n",
        "            Dropout(dropout_rate),\n",
        "            Flatten(),\n",
        "            Dense(128, activation=activation),\n",
        "            Dense(num_classes, activation=\"softmax\"),\n",
        "        ]\n",
        "    )\n",
        "    # Visualize the model\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Define our instance of the model\n",
        "\n",
        "input_shape = (80, 80, 1)\n",
        "num_classes = 6\n",
        "\n",
        "model = create_model(input_shape, num_classes, padding=\"same\", activation=\"relu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjDb-jtzI79S",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "early_stop = EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1, mode=\"min\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t07Yf2EcI79S",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, validation_data=X_val, epochs=30, callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o4e6FcuI79T",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "print(\"***********************************************************************\")\n",
        "print(\"Accuracy and Loss per Epoch:\")\n",
        "print(\"***********************************************************************\")\n",
        "loss, accuracy = model.evaluate(X_val)\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
        "\n",
        "# Plot the training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history[\"accuracy\"], label=\"accuracy\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.title(\"Accuracy\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Define a function to plot the confusion matrix\n",
        "def plot_confusion_matrix(model, dataset):\n",
        "    print(\"***********************************************************************\")\n",
        "    print(\"Confusion matrix:\")\n",
        "    print(\"***********************************************************************\")\n",
        "\n",
        "    # Get the true labels\n",
        "    y_true = []\n",
        "    for images, labels in dataset:\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "    # Get the predicted labels\n",
        "    y_pred = model.predict(dataset)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Get the class names\n",
        "    class_names = dataset.class_names\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.imshow(cm, cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion matrix\")\n",
        "    plt.colorbar()\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.xticks(range(len(class_names)), labels=class_names, rotation=45)\n",
        "    plt.yticks(range(len(class_names)), labels=class_names)\n",
        "\n",
        "    # Annotate each cell with the numeric value\n",
        "    thresh = cm.max() / 2\n",
        "    for i in range(len(class_names)):\n",
        "        for j in range(len(class_names)):\n",
        "            plt.text(\n",
        "                j,\n",
        "                i,\n",
        "                format(cm[i, j], \"d\"),\n",
        "                horizontalalignment=\"center\",\n",
        "                color=\"white\" if cm[i, j] > thresh else \"black\",\n",
        "            )\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Example usage (assuming X_val is your validation dataset)\n",
        "plot_confusion_matrix(model, X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHaZCvxpRsga"
      },
      "source": [
        "## Save our model\n",
        "\n",
        "Now that we've trained our model, we can save it for the next steps where we will want to use the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdDCs9OlI79T"
      },
      "outputs": [],
      "source": [
        "model.save(\"emotion_model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nldt4Ez1UIjl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
